import pandas as pd
import pyodbc

# Sample DataFrames with different column names for merging but same col_d
df = pd.DataFrame({
    'col_a': [1, 2, 3],
    'col_b': [4, 5, 6],
    'col_c': [7, 8, 9],
    'col_d': ['data1', 'data2', 'data3']
})

existing_data_df = pd.DataFrame({
    'col_a2': [1, 2, 10],
    'col_b2': [4, 5, 15],
    'col_c2': [7, 8, 17],
    'col_d': ['old_data1', 'old_data2', 'old_data10']  # Same col_d in both
})

# Step 1: Merge df and existing_data_df based on the different column names (except col_d)
merged_df = pd.merge(
    df, 
    existing_data_df[['col_a2', 'col_b2', 'col_c2', 'col_d']], 
    left_on=['col_a', 'col_b', 'col_c'], 
    right_on=['col_a2', 'col_b2', 'col_c2'], 
    how='left',
    suffixes=('', '_existing')
)

# Step 2: Update col_d in df with the matching data from existing_data_df where match is found
df['col_d'] = merged_df['col_d_existing'].combine_first(df['col_d'])  # Update col_d in df if match found

# Step 3: Identify the new rows (i.e., rows in df that didn't match anything in existing_data_df)
new_rows = merged_df[merged_df['col_a2'].isna()]  # Unmatched rows in df (based on merge)
df_new_rows = new_rows[['col_a', 'col_b', 'col_c', 'col_d']]  # Extract only relevant columns for new rows

# Step 4: Append the new rows to df (optional step depending on your logic)
df = pd.concat([df, df_new_rows], ignore_index=True)

# Connect to the SQL database
connection = pyodbc.connect(
    'Driver={SQL Server};'
    'Server=your_server;'
    'Database=your_database;'
    'Trusted_Connection=yes;'
)
cursor = connection.cursor()

# Step 5: Update matched rows in the SQL database
for index, row in merged_df.iterrows():
    if pd.notna(row['col_d_existing']):
        query_update = f"""
        UPDATE your_sql_table
        SET col_d = '{row['col_d_existing']}'
        WHERE col_a2 = {row['col_a']} AND col_b2 = {row['col_b']} AND col_c2 = {row['col_c']}
        """
        cursor.execute(query_update)

# Step 6: Insert new rows into the SQL database
for index, row in df_new_rows.iterrows():
    query_insert = f"""
    INSERT INTO your_sql_table (col_a2, col_b2, col_c2, col_d)
    VALUES ({row['col_a']}, {row['col_b']}, {row['col_c']}, '{row['col_d']}')
    """
    cursor.execute(query_insert)

# Commit the changes and close the connection
connection.commit()
connection.close()

# Display the updated df
print(df)
